{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaMQhwnre1gr"
      },
      "source": [
        "## Work\n",
        "1. 試比較 save_best_only 與否的差異\n",
        "2. 請僅存入將 save_weights_only 設定為 True, 並嘗試 reset ipynb 並將模型與權重重新建回並預測 x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5lcpZ1oYe1gu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras\n",
        "import tensorflow \n",
        "# Disable GPU\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVnUGfoKe1gw",
        "outputId": "bda34ed8-4921-4255-d526-5d7c27b051b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "train, test = tensorflow.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U6ae7wX_e1gw"
      },
      "outputs": [],
      "source": [
        "## 資料前處理\n",
        "def preproc_x(x, flatten=True):\n",
        "    x = x / 255.\n",
        "    if flatten:\n",
        "        x = x.reshape((len(x), -1))\n",
        "    return x\n",
        "\n",
        "def preproc_y(y, num_classes=10):\n",
        "    if y.shape[-1] == 1:\n",
        "        y = keras.utils.np_utils.to_categorical(y, num_classes)\n",
        "    return y    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7CCVn0u-e1gx"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "\n",
        "# Preproc the inputs\n",
        "x_train = preproc_x(x_train)\n",
        "x_test = preproc_x(x_test)\n",
        "\n",
        "# Preprc the outputs\n",
        "y_train = preproc_y(y_train)\n",
        "y_test = preproc_y(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WK2CbOr-e1gz"
      },
      "outputs": [],
      "source": [
        "from keras.layers import BatchNormalization\n",
        "\n",
        "\"\"\"\n",
        "建立神經網路，並加入 BN layer\n",
        "\"\"\"\n",
        "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
        "    input_layer = keras.layers.Input(input_shape)\n",
        "    \n",
        "    for i, n_units in enumerate(num_neurons):\n",
        "        if i == 0:\n",
        "            x = keras.layers.Dense(units=n_units, \n",
        "                                   activation=\"relu\", \n",
        "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
        "            x = BatchNormalization()(x)\n",
        "        else:\n",
        "            x = keras.layers.Dense(units=n_units, \n",
        "                                   activation=\"relu\", \n",
        "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
        "            x = BatchNormalization()(x)\n",
        "    \n",
        "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
        "    \n",
        "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jkJRuq3Se1g0"
      },
      "outputs": [],
      "source": [
        "## 超參數設定\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 1024\n",
        "MOMENTUM = 0.95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DYVLJfdEe1g0",
        "outputId": "e1a875d1-7c29-4e4a-a5a0-b7238eafda9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " hidden_layer1 (Dense)       (None, 512)               1573376   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " hidden_layer2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " hidden_layer3 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,742,474\n",
            "Trainable params: 1,740,682\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "49/49 [==============================] - 10s 181ms/step - loss: 2.1856 - accuracy: 0.2815 - val_loss: 2.1170 - val_accuracy: 0.1865\n",
            "Epoch 2/50\n",
            "49/49 [==============================] - 8s 172ms/step - loss: 1.7291 - accuracy: 0.3980 - val_loss: 1.9644 - val_accuracy: 0.2856\n",
            "Epoch 3/50\n",
            "49/49 [==============================] - 8s 170ms/step - loss: 1.6033 - accuracy: 0.4398 - val_loss: 1.8448 - val_accuracy: 0.3454\n",
            "Epoch 4/50\n",
            "49/49 [==============================] - 8s 171ms/step - loss: 1.5287 - accuracy: 0.4644 - val_loss: 1.7202 - val_accuracy: 0.3932\n",
            "Epoch 5/50\n",
            "49/49 [==============================] - 8s 170ms/step - loss: 1.4729 - accuracy: 0.4838 - val_loss: 1.6501 - val_accuracy: 0.4155\n",
            "Epoch 6/50\n",
            "49/49 [==============================] - 12s 237ms/step - loss: 1.4259 - accuracy: 0.5009 - val_loss: 1.5899 - val_accuracy: 0.4368\n",
            "Epoch 7/50\n",
            "49/49 [==============================] - 10s 200ms/step - loss: 1.3870 - accuracy: 0.5131 - val_loss: 1.5451 - val_accuracy: 0.4530\n",
            "Epoch 8/50\n",
            "49/49 [==============================] - 8s 172ms/step - loss: 1.3504 - accuracy: 0.5273 - val_loss: 1.5128 - val_accuracy: 0.4663\n",
            "Epoch 9/50\n",
            "49/49 [==============================] - 8s 171ms/step - loss: 1.3153 - accuracy: 0.5425 - val_loss: 1.5016 - val_accuracy: 0.4674\n",
            "Epoch 10/50\n",
            "49/49 [==============================] - 8s 172ms/step - loss: 1.2830 - accuracy: 0.5522 - val_loss: 1.4834 - val_accuracy: 0.4799\n",
            "Epoch 11/50\n",
            "49/49 [==============================] - 9s 180ms/step - loss: 1.2559 - accuracy: 0.5615 - val_loss: 1.4889 - val_accuracy: 0.4746\n",
            "Epoch 12/50\n",
            "49/49 [==============================] - 8s 170ms/step - loss: 1.2261 - accuracy: 0.5738 - val_loss: 1.4759 - val_accuracy: 0.4782\n",
            "Epoch 13/50\n",
            "49/49 [==============================] - 8s 170ms/step - loss: 1.2018 - accuracy: 0.5820 - val_loss: 1.4775 - val_accuracy: 0.4801\n",
            "Epoch 14/50\n",
            "49/49 [==============================] - 8s 172ms/step - loss: 1.1741 - accuracy: 0.5929 - val_loss: 1.4608 - val_accuracy: 0.4872\n",
            "Epoch 15/50\n",
            "49/49 [==============================] - 9s 191ms/step - loss: 1.1487 - accuracy: 0.6035 - val_loss: 1.4574 - val_accuracy: 0.4837\n",
            "Epoch 16/50\n",
            "49/49 [==============================] - 8s 173ms/step - loss: 1.1257 - accuracy: 0.6118 - val_loss: 1.4609 - val_accuracy: 0.4872\n",
            "Epoch 17/50\n",
            "49/49 [==============================] - 9s 179ms/step - loss: 1.1021 - accuracy: 0.6214 - val_loss: 1.4493 - val_accuracy: 0.4908\n",
            "Epoch 18/50\n",
            "49/49 [==============================] - 8s 171ms/step - loss: 1.0770 - accuracy: 0.6295 - val_loss: 1.4534 - val_accuracy: 0.4919\n",
            "Epoch 19/50\n",
            "49/49 [==============================] - 9s 179ms/step - loss: 1.0550 - accuracy: 0.6388 - val_loss: 1.4629 - val_accuracy: 0.4856\n",
            "Epoch 20/50\n",
            "49/49 [==============================] - 8s 168ms/step - loss: 1.0338 - accuracy: 0.6470 - val_loss: 1.4650 - val_accuracy: 0.4897\n",
            "Epoch 21/50\n",
            "49/49 [==============================] - 8s 171ms/step - loss: 1.0106 - accuracy: 0.6564 - val_loss: 1.4596 - val_accuracy: 0.4941\n",
            "Epoch 22/50\n",
            "49/49 [==============================] - 8s 171ms/step - loss: 0.9906 - accuracy: 0.6649 - val_loss: 1.4761 - val_accuracy: 0.4919\n",
            "Epoch 23/50\n",
            "49/49 [==============================] - 8s 169ms/step - loss: 0.9680 - accuracy: 0.6712 - val_loss: 1.4717 - val_accuracy: 0.4908\n",
            "Epoch 24/50\n",
            "49/49 [==============================] - 9s 189ms/step - loss: 0.9464 - accuracy: 0.6796 - val_loss: 1.4618 - val_accuracy: 0.4958\n",
            "Epoch 25/50\n",
            "49/49 [==============================] - 8s 172ms/step - loss: 0.9251 - accuracy: 0.6892 - val_loss: 1.4890 - val_accuracy: 0.4906\n",
            "Epoch 26/50\n",
            "49/49 [==============================] - 9s 189ms/step - loss: 0.9055 - accuracy: 0.6955 - val_loss: 1.4667 - val_accuracy: 0.4999\n",
            "Epoch 27/50\n",
            "49/49 [==============================] - 8s 170ms/step - loss: 0.8845 - accuracy: 0.7038 - val_loss: 1.4762 - val_accuracy: 0.4937\n",
            "Epoch 28/50\n",
            "49/49 [==============================] - 8s 169ms/step - loss: 0.8621 - accuracy: 0.7153 - val_loss: 1.4846 - val_accuracy: 0.4915\n",
            "Epoch 29/50\n",
            "49/49 [==============================] - 8s 171ms/step - loss: 0.8433 - accuracy: 0.7224 - val_loss: 1.4948 - val_accuracy: 0.4949\n",
            "Epoch 30/50\n",
            "49/49 [==============================] - 8s 173ms/step - loss: 0.8239 - accuracy: 0.7282 - val_loss: 1.4906 - val_accuracy: 0.4918\n",
            "Epoch 31/50\n",
            "49/49 [==============================] - 8s 173ms/step - loss: 0.8052 - accuracy: 0.7372 - val_loss: 1.4969 - val_accuracy: 0.5010\n",
            "Epoch 32/50\n",
            "49/49 [==============================] - 8s 173ms/step - loss: 0.7846 - accuracy: 0.7456 - val_loss: 1.5064 - val_accuracy: 0.4950\n",
            "Epoch 33/50\n",
            "49/49 [==============================] - 8s 172ms/step - loss: 0.7668 - accuracy: 0.7524 - val_loss: 1.5105 - val_accuracy: 0.4979\n",
            "Epoch 34/50\n",
            "49/49 [==============================] - 8s 173ms/step - loss: 0.7454 - accuracy: 0.7602 - val_loss: 1.5286 - val_accuracy: 0.4904\n",
            "Epoch 35/50\n",
            "49/49 [==============================] - 8s 171ms/step - loss: 0.7259 - accuracy: 0.7672 - val_loss: 1.5284 - val_accuracy: 0.4901\n",
            "Epoch 36/50\n",
            "49/49 [==============================] - 9s 174ms/step - loss: 0.7075 - accuracy: 0.7755 - val_loss: 1.5366 - val_accuracy: 0.4922\n",
            "Epoch 37/50\n",
            "49/49 [==============================] - 8s 172ms/step - loss: 0.6917 - accuracy: 0.7811 - val_loss: 1.5482 - val_accuracy: 0.4905\n",
            "Epoch 38/50\n",
            "49/49 [==============================] - 9s 174ms/step - loss: 0.6698 - accuracy: 0.7908 - val_loss: 1.5501 - val_accuracy: 0.4939\n",
            "Epoch 39/50\n",
            "49/49 [==============================] - 8s 170ms/step - loss: 0.6525 - accuracy: 0.7972 - val_loss: 1.5713 - val_accuracy: 0.4922\n",
            "Epoch 40/50\n",
            "49/49 [==============================] - 8s 170ms/step - loss: 0.6344 - accuracy: 0.8042 - val_loss: 1.5767 - val_accuracy: 0.4926\n",
            "Epoch 41/50\n",
            "49/49 [==============================] - 8s 168ms/step - loss: 0.6137 - accuracy: 0.8136 - val_loss: 1.5968 - val_accuracy: 0.4925\n",
            "Epoch 42/50\n",
            "49/49 [==============================] - 8s 171ms/step - loss: 0.5984 - accuracy: 0.8188 - val_loss: 1.5998 - val_accuracy: 0.4897\n",
            "Epoch 43/50\n",
            "49/49 [==============================] - 8s 170ms/step - loss: 0.5829 - accuracy: 0.8254 - val_loss: 1.6412 - val_accuracy: 0.4892\n",
            "Epoch 44/50\n",
            "31/49 [=================>............] - ETA: 2s - loss: 0.5588 - accuracy: 0.8376"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9a9d51ab4f5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_ckpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m          )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 載入 Callbacks\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model_ckpt = ModelCheckpoint(filepath=\"./tmp.h5\", \n",
        "                             monitor=\"val_loss\", \n",
        "                             save_best_only=True)\n",
        "\n",
        "results = {}\n",
        "model = build_mlp(input_shape=x_train.shape[1:])\n",
        "model.summary()\n",
        "optimizer = tensorflow.keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
        "\n",
        "model.fit(x_train, y_train, \n",
        "          epochs=EPOCHS, \n",
        "          batch_size=BATCH_SIZE, \n",
        "          validation_data=(x_test, y_test), \n",
        "          shuffle=True,\n",
        "          callbacks=[model_ckpt]\n",
        "         )\n",
        "\n",
        "# Collect results\n",
        "train_loss = model.history.history[\"loss\"]\n",
        "valid_loss = model.history.history[\"val_loss\"]\n",
        "train_acc = model.history.history[\"accuracy\"]\n",
        "valid_acc = model.history.history[\"val_accuracy\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load back\n",
        "model = keras.models.load_model(\"./tmp.h5\")\n",
        "loss_loadback, acc_loadback = model.evaluate(x_test, y_test)\n",
        "print(loss_loadback, acc_loadback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eNdQNdWgUQ-",
        "outputId": "4eb1309a-5ec0-47b8-8678-8ee3c76f53fc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 1.4493 - accuracy: 0.4908\n",
            "1.4493390321731567 0.49079999327659607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "Os4l405se1g1",
        "outputId": "5f3d1984-b438-4269-aeb9-d128d2eb0e6f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4609a5bbb928>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"valid loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_loadback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loss' is not defined"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
        "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
        "plt.hlines(y=loss_loadback, xmin=0, xmax=len(train_loss), colors='r', linestyles='--')\n",
        "plt.legend()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
        "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
        "plt.hlines(y=acc_loadback, xmin=0, xmax=len(train_loss), colors='r', linestyles='--')\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Day086_CB_ModelCheckPoint_作業.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}